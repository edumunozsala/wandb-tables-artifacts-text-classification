{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6Y7i1ZNSn20"
   },
   "source": [
    "# Text Classification on news and W&B Tables and Artifacts\n",
    "\n",
    "# Exploratory Data Analysis on Text Data\n",
    "\n",
    "We can read this concept definition on Wikipedia: **\"exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods.\"**. This step is absolutely necessary and has a huge impact on the final result of a model, this analysis will tell us what type of transformation we need to apply on the dataset.\n",
    "\n",
    "When we face a machine learning problem, we must begin by analyzing the input data set, seeking to identify its characteristics and anomalies. In this notebook, we will explore the dataset, collect some attributes and analyze the main features and characteristics of the data. Then we will upload the raw data and the extra information to W&B and make an EDA on the dataset. \n",
    "\n",
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kN4Z2vqRSn28"
   },
   "source": [
    "For the very first time, we need to download and install the following libraries that we will use to plot and visualize some interesting resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10698,
     "status": "ok",
     "timestamp": 1679160330052,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "sTVA2orAwQ61",
    "outputId": "c2501ca4-543a-4ada-f77f-591e42a08aa6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.0.3)\n",
      "Requirement already satisfied: nltk in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: gensim in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.3.1)\n",
      "Requirement already satisfied: wordcloud in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.9.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: click in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: joblib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: pillow in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wordcloud) (10.0.0)\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->wordcloud) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->wordcloud) (4.42.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->wordcloud) (5.12.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk scikit-learn gensim wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/studio-lab-user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "#import gensim\n",
    "#from gensim.summarization.textcleaner import split_sentences\n",
    "#import unicodedata\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Load the library with the CountVectorizer method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yS-N2DHnSn3A"
   },
   "source": [
    "We will define some global variables to be use during our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "abo2TvmDqAnV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL When running out of Colab \n",
    "root_folder = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1679158749563,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "iaray6XcqAnW"
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL When running ON Colab \n",
    "from google.colab import drive\n",
    "root_folder = '/content/drive/MyDrive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1679158755968,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "a9n9nQd0Sn3A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set the path where the datafiles are stored\n",
    "# Global parameters\n",
    "data_folder_name='data'\n",
    "output_folder = 'W&B-user-complaints-classification/data_analysis'\n",
    "train_filename='complaints_processed.csv'\n",
    "\n",
    "# Variable for data directory\n",
    "data_path = os.path.abspath(os.path.join(root_folder, data_folder_name))\n",
    "train_filenamepath = os.path.abspath(os.path.join(data_path, train_filename))\n",
    "output_path = os.path.abspath(os.path.join(root_folder, output_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1679158768007,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "RR_tq9oX0vdH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define some global variables for text processing\n",
    "punc = string.punctuation\n",
    "punctuation = string.punctuation.replace('.', '')\n",
    "#Create the list of stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoYdZ1WYSn3A"
   },
   "source": [
    "### Loading the dataset\n",
    "First step, load the whole dataset hosted locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27826,
     "status": "ok",
     "timestamp": 1679158800557,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "sMEuZ0pfTXGF",
    "outputId": "994893ca-b57f-4bdd-f402-0f21e6be5a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# When running in Colab\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2719,
     "status": "ok",
     "timestamp": 1679158829893,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "Av-cIl9jSn3E",
    "outputId": "ccf0485a-132b-44d5-a661-a25adce96572",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            product                                          narrative\n",
      "0       credit_card  purchase order day shipping amount receive pro...\n",
      "1       credit_card  forwarded message date tue subject please inve...\n",
      "2    retail_banking  forwarded message cc sent friday pdt subject f...\n",
      "3  credit_reporting  payment history missing credit report speciali...\n",
      "4  credit_reporting  payment history missing credit report made mis...\n",
      "Num rows:  162421\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the file system\n",
    "data = pd.read_csv(train_filenamepath, header=0, usecols=[1,2])\n",
    "print(data.head(5))\n",
    "print('Num rows: ',len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q9hCKaqSn3F"
   },
   "source": [
    "# Data Definition\n",
    "This dataset was downloaded from Kaggle, the Consumer Complaints Dataset, and consist of about 150,000 rows containing the product category and the text of the user complaint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDsAIzcsSn3F"
   },
   "source": [
    "Lets show the data structure and an example of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1679158838216,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "svh1GqHOSn3G",
    "outputId": "1dfa6f10-96e3-4dde-8a96-99ff0992fd4c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162421 entries, 0 to 162420\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   product    162421 non-null  object\n",
      " 1   narrative  162411 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1679158841879,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "QHaaSC1BSn3G",
    "outputId": "e512f2a6-6599-42ca-aa34-a53012a00a7f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_card \n",
      " purchase order day shipping amount receive product week sent followup email exact verbiage paid two day shipping received order company responded im sorry inform due unusually high order volume order shipped several week stock since early due high demand although continuing take order guaranteeing receive order place due time mask order exact shipping date right however guarantee ship soon soon delivers product u getting small shipment shipping first come first served basis appreciate patience fulfill order quickly recommend keeping order lose place line cancel distributor stock moment prefer cancel please note ask via email cancel accordance cancellation policy agreed checkout electronic inventory online requested order canceled refund issued canceled order sent verification order canceled refunded item particulate respirator refunded subtotal shipping tax total usd visa ending refund called disputed amount stated nothing needed submitted address issue recharged item removing called back dispute amount transaction rebillmerchandiserobert ca purchased thu posted wed purchased appears statement transaction rebill ca u followed see status case submitted documentation showing canceled order supposed submit refund called back speak manager case stated dispute ruled favor charge removed card capital one removed purchase bill purchase adjustmentmerchandiserobert j posted fri purchased appears statement purchase adjustment capital one recharges amount transaction rebillmerchandiserobert j purchased thu posted mon purchased appears statement transaction rebill called capital one requested recharge stated visa ruled case pretended remove purchase knew anything case manager ruling favor \n",
      "\n",
      "credit_card \n",
      " forwarded message date tue subject please investigate comenity bank retailer card scam sent hello name scammed comenity bank credit card provider company childrens place new york forever victoria secret original credit comenity bank lower limit began charge overage fee along late fee began pay close attention card find limit also changed well incurring overage late fee reached company comenity bank stated would change credit limit original limit reached told summit payment account corrected comenity bank credit card impacted credit score plummeted negative status im currently paying price due corruption affected detrimental way debt due company charging overage fee well late fee even initial credit limit fluctuating tremendously company charge major fee account willing correct account nervous said attorney reason im reaching im employee company ruining credit plz help name contact info thank \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['product'][0],'\\n',data['narrative'][0],'\\n')\n",
    "print(data['product'][1],'\\n',data['narrative'][1],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6rdWi55Sn3H"
   },
   "source": [
    "# Descriptive statictics\n",
    "\n",
    "First of all, we extract the basics statistics: count of rows, unique rows, frequencies,... This atributes in the text data will tell us if we need to remove repeated rows or how many rows contains null values in any column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1679158846318,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "5q8QFU_rSn3H",
    "outputId": "d3508311-a149-41b3-fc44-1bb2f4640e6e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>162421</td>\n",
       "      <td>162411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>124472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>victim identity notified collection creditor s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>91179</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 product                                          narrative\n",
       "count             162421                                             162411\n",
       "unique                 5                                             124472\n",
       "top     credit_reporting  victim identity notified collection creditor s...\n",
       "freq               91179                                                739"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of examples and unique values\n",
    "#print('Dataset examples: ', len(data))\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9zTpAQISn3I"
   },
   "source": [
    "**Conclusion from statistics**\n",
    "\n",
    "We can observe we have 5 target labels and almost 40,000 duplicated texts, which we have to remove.\n",
    "\n",
    "Reading the previous table we can observe that there are some rows with a null value or repetaed in the variable `description`. So our first step would be to drop those rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN0vEt6RqeE7"
   },
   "source": [
    "Check for null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1679158850619,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "Mf4vneZXqhL9",
    "outputId": "89ef2329-d56c-4aa3-e381-a5d283cec0a3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product       0\n",
       "narrative    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jq_GgYzVBwYE"
   },
   "source": [
    "Remove rows with null values and drop duplicates narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1679158866844,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "17eO8sMOSn3I",
    "outputId": "214ec928-b0f1-40ad-fdda-a1265dda2447",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124472</td>\n",
       "      <td>124472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>124472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>56240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 product narrative\n",
       "count             124472    124472\n",
       "unique                 5    124472\n",
       "top     credit_reporting      name\n",
       "freq               56240         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with null values\n",
    "data.dropna(inplace=True)\n",
    "# Drop duplicates on narrative column\n",
    "data.drop_duplicates(subset=['narrative'], keep='first', inplace=True, ignore_index=True)\n",
    "#Recreate the dataframe index\n",
    "#data.reset_index(drop=True,inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1679158876458,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "vauzrIpdCRxr",
    "outputId": "cb233daf-16c2-400c-e322-afcd6e549b9e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>purchase order day shipping amount receive pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>forwarded message date tue subject please inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retail_banking</td>\n",
       "      <td>forwarded message cc sent friday pdt subject f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>payment history missing credit report speciali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>payment history missing credit report made mis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            product                                          narrative\n",
       "0       credit_card  purchase order day shipping amount receive pro...\n",
       "1       credit_card  forwarded message date tue subject please inve...\n",
       "2    retail_banking  forwarded message cc sent friday pdt subject f...\n",
       "3  credit_reporting  payment history missing credit report speciali...\n",
       "4  credit_reporting  payment history missing credit report made mis..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goal is collecting data for a W&B project and demo how to work with artifacts and reports We want to sample the dataset to extract less data in order to reduce processing time amd storage resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "credit_reporting       56240\n",
       "debt_collection        21057\n",
       "mortgages_and_loans    18723\n",
       "credit_card            14983\n",
       "retail_banking         13469\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets extract a sample, about half of the data 60,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = data.groupby('product', group_keys=False).apply(lambda x: x.sample(frac=0.5)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>company reporting three unknown account credit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>recall record boss requested various occasion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>merchant committed fraud shipping incorrect it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>sent debt validation letter company failed val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>phoenix financial service llc company claiming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>received email mastercard apply application ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mortgages_and_loans</td>\n",
       "      <td>closed mortgage newrez llc due refinancing tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>getting many email alert experian credit compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mortgages_and_loans</td>\n",
       "      <td>may concern moved california due job relocatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>filed bankruptcy included part debt bankruptcy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               product                                          narrative\n",
       "0      debt_collection  company reporting three unknown account credit...\n",
       "1      debt_collection  recall record boss requested various occasion ...\n",
       "2          credit_card  merchant committed fraud shipping incorrect it...\n",
       "3      debt_collection  sent debt validation letter company failed val...\n",
       "4      debt_collection  phoenix financial service llc company claiming...\n",
       "5     credit_reporting  received email mastercard apply application ti...\n",
       "6  mortgages_and_loans  closed mortgage newrez llc due refinancing tol...\n",
       "7     credit_reporting  getting many email alert experian credit compa...\n",
       "8  mortgages_and_loans  may concern moved california due job relocatio...\n",
       "9     credit_reporting  filed bankruptcy included part debt bankruptcy..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.sample(frac=1, ignore_index=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the count of examples for every target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "credit_reporting       28120\n",
       "debt_collection        10528\n",
       "mortgages_and_loans     9362\n",
       "credit_card             7492\n",
       "retail_banking          6734\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk74XkxrSn3K"
   },
   "source": [
    "## Cleaning the data\n",
    "\n",
    "This dataset was already preprocessed and cleaned: lowercased, stopwords removed, etc. We do not need to apply this transformations, but it is very rare to work with a cleaned dataset.\n",
    "\n",
    "**DO NOT APPLY THIS SECTION**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1678645014287,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "BWsydnBfCfug",
    "outputId": "aa066a93-e8e9-4c4a-d157-e60a344b9510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    purchase order day shipping amount receive pro...\n",
       "1    forwarded message date tue subject please inve...\n",
       "2    forwarded message cc sent friday pdt subject f...\n",
       "3    payment history missing credit report speciali...\n",
       "4    payment history missing credit report made mis...\n",
       "5    payment history missing credit report made mis...\n",
       "6    va date complaint experian credit bureau invol...\n",
       "7    account reported abbreviated name full name se...\n",
       "8    account reported abbreviated name full name se...\n",
       "9    usdoexxxx account reported abbreviated name fu...\n",
       "Name: narrative, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['narrative'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwB_1KScSn3K"
   },
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    ''' Remove URLs from the text'''\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "# Remove html tag\n",
    "def remove_html(text):\n",
    "    ''' Remove HTML tags from the text'''\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "def remove_mention(text):\n",
    "    ''' Remove mentions from the text'''\n",
    "    url = re.compile(r'@\\S*')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_mult_spaces(text):\n",
    "    ''' Reduce multispace to one single space'''\n",
    "    re_mult_space = re.compile(r\"  *\") # replace multiple spaces with just one\n",
    "    return re_mult_space.sub(r' ', text)\n",
    "\n",
    "def remove_non_character(text):\n",
    "    ''' Remove some non alphanumeric characters'''\n",
    "    url = re.compile(r'\\x89\\S*|\\x9b\\S*|\\x92\\S*|x93\\S*|\\x8a\\S*|\\x8f\\S*|\\x9d\\S*|\\x8c\\S*|\\x91\\S*|\\x87\\S*|\\x88\\S*|\\x82\\S*')\n",
    "    #url = re.compile(r'\\x\\d+\\S*')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_punctuation(text, punctuation):\n",
    "    ''' Remove punctuation from the text'''\n",
    "    table=str.maketrans('','',punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    ''' Remove emojis from the text'''\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_CTL(text):\n",
    "    ''' Remove end of line from the text'''\n",
    "    url = re.compile(r'\\n')\n",
    "    return url.sub(r' ',text)\n",
    "\n",
    "def remove_hashtag(text):\n",
    "    ''' Remove hashtags from the text'''\n",
    "    url = re.compile(r'#\\S*')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    ''' Transform unicode symbols to ascii'''\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYRiLc8TrZ5c"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    ''' Clean the input text using common techniques'''\n",
    "    new_text = text.map(lambda x: x.lower())\n",
    "    new_text=new_text.apply(lambda x : unicode_to_ascii(x))\n",
    "    #new_text=new_text.apply(lambda x : replace_mapping(x, special_mapping))\n",
    "    new_text=new_text.apply(lambda x : remove_URL(x))\n",
    "    new_text=new_text.apply(lambda x : remove_html(x))\n",
    "    new_text=new_text.apply(lambda x : remove_emoji(x))\n",
    "    new_text=new_text.apply(lambda x : remove_CTL(x))\n",
    "    #new_text=new_text.apply(lambda x : expand_contractions(x,contraction_mapping))\n",
    "    new_text=new_text.apply(lambda x : remove_non_character(x))\n",
    "    new_text=new_text.apply(lambda x : remove_mention(x))\n",
    "    new_text=new_text.apply(lambda x : remove_hashtag(x))\n",
    "    #new_text=new_text.apply(lambda x : remove_punctuation(x, punctuation))\n",
    "    new_text=new_text.apply(lambda x : remove_mult_spaces(x))\n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25643,
     "status": "ok",
     "timestamp": 1634317650933,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "36MkUyy8rvmK",
    "outputId": "2bf748ff-f2dc-48ec-ff4a-c81248c976ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Apply the cleaning functions to the review text\n",
    "data_text = clean_text(dataset['review_es'])\n",
    "#Checking the results\n",
    "print(len(data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1634317692357,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "zk3for0uSn3K",
    "outputId": "243d0617-e322-4a40-f956-3a2d65973864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           review_es sentimiento\n",
      "0  Uno de los otros críticos ha mencionado que de...    positivo\n",
      "1  Una pequeña pequeña producción.La técnica de f...    positivo\n",
      "2  Pensé que esta era una manera maravillosa de p...    positivo\n",
      "3  Básicamente, hay una familia donde un niño peq...    negativo\n",
      "4  El \"amor en el tiempo\" de Petter Mattei es una...    positivo\n",
      "                                                review_es sentimiento\n",
      "count                                               50000       50000\n",
      "unique                                              49599           2\n",
      "top     Hilarante, limpio, alegre y digno de cita.¿Qué...    positivo\n",
      "freq                                                    4       25000\n"
     ]
    }
   ],
   "source": [
    "# Print some examples and statistics\n",
    "print(dataset.head(5))\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1634317702020,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "R3NxNxVWSn3L",
    "outputId": "9576372d-0e76-47d3-b0ac-f23d82ff4c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "una pequena pequena produccion.la tecnica de filmacion es muy incuestionable, muy antigua, la moda de la bbc y le da una sensacion de realismo reconfortante, y, a veces, incomodo, y, a veces, a la pieza.los actores son extremadamente bien elegidos, michael sheen, no solo \"tiene todo el polari\", ¡pero tiene todas las voces por palmaditas!realmente puede ver la edicion perfecta guiada por las referencias a las entradas del diario de williams, no solo vale la pena la observacion, pero es una pieza imperrementemente escrita y realizada.una produccion magistral sobre uno de los grandes maestros de la comedia y su vida.el realismo realmente llega a casa con las pequenas cosas: la fantasia del guardia que, en lugar de usar las tecnicas de \"sueno\" tradicionales permanece solido, entonces desaparece.se desempena nuestro conocimiento y nuestros sentidos, particularmente con las escenas relacionadas con orton y halliwell y los conjuntos (particularmente de su apartamento con murales de halliwell que decoran cada superficie) estan terriblemente bien hechos. \n",
      " positivo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned and tokenize text in the dataframe\n",
    "dataset['review_es']=data_text\n",
    "#dataset['name']=data_headlines\n",
    "print(dataset['review_es'][1],'\\n',dataset['sentimiento'][1],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOC0eN-RDfex"
   },
   "source": [
    "# Analyze data balance\n",
    "\n",
    "One mandatory task in any classification task is to analyze the count of rows for every target label to avoid or limit the impact of unbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1679158968079,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "tCpR7WNBD_h6",
    "outputId": "98c10e68-c13c-4c1f-ecfd-97a9d4522918",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "credit_reporting       56240\n",
       "debt_collection        21057\n",
       "mortgages_and_loans    18723\n",
       "credit_card            14983\n",
       "retail_banking         13469\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL-fk5-eESw9"
   },
   "source": [
    "### Category 'credit_reporting'.\n",
    "\n",
    "To limit this unbalanced feature we will downsample our data to only 15,000 rows in the categories: `credit_reporting`,`debt_collection`, mortgages_and_loans` . And for the sake of this experiment this step will reduce our data volume and we can perform a shorter and cheaper training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1679158970535,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "pInTKIMSE-AX",
    "outputId": "b1e3e54c-a3e0-422e-8849-e82ea68743fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56240, 2)\n",
      "(21057, 2)\n",
      "(18723, 2)\n"
     ]
    }
   ],
   "source": [
    "credit = data[data[\"product\"] == \"credit_reporting\"]\n",
    "debt  = data[data[\"product\"] == \"debt_collection\"]\n",
    "mortgage  = data[data[\"product\"] == \"mortgages_and_loans\"]\n",
    "print(credit.shape)\n",
    "print(debt.shape)\n",
    "print(mortgage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679158973134,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "3acoCZExHuNk",
    "outputId": "71444ac4-e539-4d62-d736-95eed89d0002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 2)\n",
      "(15000, 2)\n",
      "(15000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Sample the three columns in the dataset to extract 15,000 rows\n",
    "credit = credit.sample(n=15000, replace=False, random_state=42)\n",
    "debt = debt.sample(n=15000, replace=False, random_state=42)\n",
    "mortgage = mortgage.sample(n=15000, replace=False, random_state=42)\n",
    "print(credit.shape)\n",
    "print(debt.shape)\n",
    "print(mortgage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh8vd7NdmBH0"
   },
   "source": [
    "Now, we build a new dataframe concatening these samples and the others two originals columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1679159012845,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "kIez29jzI7b4",
    "outputId": "72a43814-fd30-4e49-dcce-acf2fb188d6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b93296d6-3a73-40a7-9734-6bd35214b536\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>please remove highlighted account credit repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>experian violation section fair credit reporti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>experian continues report false information cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>listed belong someone stole used social securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>complained year equifax done nothing update co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b93296d6-3a73-40a7-9734-6bd35214b536')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b93296d6-3a73-40a7-9734-6bd35214b536 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b93296d6-3a73-40a7-9734-6bd35214b536');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            product                                          narrative\n",
       "0  credit_reporting  please remove highlighted account credit repor...\n",
       "1  credit_reporting  experian violation section fair credit reporti...\n",
       "2  credit_reporting  experian continues report false information cr...\n",
       "3  credit_reporting  listed belong someone stole used social securi...\n",
       "4  credit_reporting  complained year equifax done nothing update co..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced=pd.concat([credit, debt, mortgage, data[data[\"product\"] == \"credit_card\"], data[data[\"product\"] == \"retail_banking\"]], ignore_index=True)\n",
    "data_balanced.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1679078135900,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "lgKIQFbtJNrO",
    "outputId": "8b6a8f5a-2d31-4829-ae35-b8bca21c7462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_reporting       15000\n",
       "debt_collection        15000\n",
       "mortgages_and_loans    15000\n",
       "credit_card            14983\n",
       "retail_banking         13469\n",
       "Name: product, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the count of rows for every category\n",
    "data_balanced['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9MoTFfxSn3L"
   },
   "source": [
    "# Exploring relevant features in the data\n",
    "\n",
    "In this section we will create some additional features that provide relevant information about the composition of our texts. The following list explains different ideas for creating new features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hypiRYpTSn3L"
   },
   "source": [
    "#### Statistical Count Features from headlines and text\n",
    "- Sentence Count - Total number of sentences in the text\n",
    "- Word Count - Total number of words in the text\n",
    "- Character Count - Total number of characters in the text excluding spaces\n",
    "- Sentence density - Number of sentences relative to the number of words\n",
    "- Word Density - Average length of the words used in the text\n",
    "- Punctuation Count - Total number of punctuations used in the text\n",
    "- Stopwords Count - Total number of common stopwords in the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw1ElcwGSn3M"
   },
   "source": [
    "Lets define some helpers function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1679159031019,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "w5e598ZsSn3M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_stopwords(text, stopwords):\n",
    "    ''' Return the number of stopwords in the text\n",
    "        Input:\n",
    "            - text: string\n",
    "            - stopwords: list of string, containing the stopwords\n",
    "        Output:\n",
    "            - int, number of stopwords in the text argument\n",
    "    '''\n",
    "    word_tokens = word_tokenize(text) #splitta i pezzi\n",
    "    stopwords_x = [w for w in word_tokens if w in stopwords]\n",
    "    \n",
    "    return len(stopwords_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split sentences we need to load a module fro NLTK library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['una pequena pequena produccion.',\n",
       " 'la tecnica de filmacion es muy incuestionable, muy antigua.',\n",
       " 'la moda de la bbc y le da una sensacion de realismo reconfortante, y, a veces, incomodo, y, a veces, a la pieza.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"una pequena pequena produccion. la tecnica de filmacion es muy incuestionable, muy antigua. la moda de la bbc y le da una sensacion de realismo reconfortante, y, a veces, incomodo, y, a veces, a la pieza.\"\n",
    "#print('\\n-----\\n'.join(tokenizer.tokenize(t)))\n",
    "#tokenizer.tokenize(t)\n",
    "sent_tokenize(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPoVuz4oSn3M"
   },
   "source": [
    "It is time to calculate every new feature previously listed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 42441,
     "status": "ok",
     "timestamp": 1679159077648,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "TjIVMwzhSn3M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new variable containing the number of sentences in the text\n",
    "dataset['sent_count'] = dataset['narrative'].apply(lambda x : len(sent_tokenize(x)))\n",
    "# Create a new variable containing the number of word in the text\n",
    "dataset['word_count'] = dataset['narrative'].apply(lambda x : len(x.split()))\n",
    "# Create a new variable containing the number of characters in the text\n",
    "dataset['char_count'] = dataset['narrative'].apply(lambda x : len(x.replace(\" \",\"\")))\n",
    "# Create a new variable containing the density of words in the text\n",
    "dataset['word_density'] = dataset['char_count'] / (dataset['word_count'] + 1)\n",
    "# Create a new variable containing the density of sentences in the text\n",
    "dataset['sent_density'] = dataset['word_count'] / (dataset['sent_count'] + 1)\n",
    "# Create a new variable containing the number of punctuations in the text\n",
    "dataset['punc_count'] = dataset['narrative'].apply(lambda x : len([a for a in x if a in punc]))\n",
    "\n",
    "# Stopwords\n",
    "# Create a new variable containing the number of stopwords in the text\n",
    "dataset['stopw_count'] =  dataset['narrative'].apply(lambda x : count_stopwords(x, stopwords))\n",
    "# Create a new variable containing the density of stopwords in the text\n",
    "dataset['stopw_density'] = dataset['stopw_count'] / (dataset['word_count'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1679159103470,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "c-59mcwJnjA_",
    "outputId": "85ea19c2-f8f6-4936-da2b-b1c6f3968805",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>sent_density</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>stopw_count</th>\n",
       "      <th>stopw_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62236.0</td>\n",
       "      <td>62236.000000</td>\n",
       "      <td>62236.000000</td>\n",
       "      <td>62236.000000</td>\n",
       "      <td>62236.000000</td>\n",
       "      <td>62236.0</td>\n",
       "      <td>62236.000000</td>\n",
       "      <td>62236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>86.999470</td>\n",
       "      <td>546.198727</td>\n",
       "      <td>6.072418</td>\n",
       "      <td>43.499735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023170</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>109.695701</td>\n",
       "      <td>709.913553</td>\n",
       "      <td>0.606672</td>\n",
       "      <td>54.847851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229663</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>5.708512</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>6.090542</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>6.471429</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2685.000000</td>\n",
       "      <td>17307.000000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>1342.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sent_count    word_count    char_count  word_density  sent_density  \\\n",
       "count     62236.0  62236.000000  62236.000000  62236.000000  62236.000000   \n",
       "mean          1.0     86.999470    546.198727      6.072418     43.499735   \n",
       "std           0.0    109.695701    709.913553      0.606672     54.847851   \n",
       "min           1.0      1.000000      4.000000      2.000000      0.500000   \n",
       "25%           1.0     31.000000    190.000000      5.708512     15.500000   \n",
       "50%           1.0     58.000000    359.000000      6.090542     29.000000   \n",
       "75%           1.0    104.000000    650.000000      6.471429     52.000000   \n",
       "max           1.0   2685.000000  17307.000000     29.750000   1342.500000   \n",
       "\n",
       "       punc_count   stopw_count  stopw_density  \n",
       "count     62236.0  62236.000000   62236.000000  \n",
       "mean          0.0      0.023170       0.000281  \n",
       "std           0.0      0.229663       0.003012  \n",
       "min           0.0      0.000000       0.000000  \n",
       "25%           0.0      0.000000       0.000000  \n",
       "50%           0.0      0.000000       0.000000  \n",
       "75%           0.0      0.000000       0.000000  \n",
       "max           0.0     22.000000       0.166667  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izT6njic3S0_"
   },
   "source": [
    "We can remove the columns about stopwords and sentences because our dataset is already cleaned, as we can observe there are not any stopwords eiother sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1679159119710,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "KAfJnRuN3j2R",
    "outputId": "a59fcb3c-c057-41fc-fbc7-2994a73d8589",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>sent_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>company reporting three unknown account credit...</td>\n",
       "      <td>21</td>\n",
       "      <td>138</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>recall record boss requested various occasion ...</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>merchant committed fraud shipping incorrect it...</td>\n",
       "      <td>294</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>sent debt validation letter company failed val...</td>\n",
       "      <td>36</td>\n",
       "      <td>245</td>\n",
       "      <td>6.621622</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>phoenix financial service llc company claiming...</td>\n",
       "      <td>39</td>\n",
       "      <td>244</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           product                                          narrative  \\\n",
       "0  debt_collection  company reporting three unknown account credit...   \n",
       "1  debt_collection  recall record boss requested various occasion ...   \n",
       "2      credit_card  merchant committed fraud shipping incorrect it...   \n",
       "3  debt_collection  sent debt validation letter company failed val...   \n",
       "4  debt_collection  phoenix financial service llc company claiming...   \n",
       "\n",
       "   word_count  char_count  word_density  sent_density  \n",
       "0          21         138      6.272727          10.5  \n",
       "1          13          98      7.000000           6.5  \n",
       "2         294        2006      6.800000         147.0  \n",
       "3          36         245      6.621622          18.0  \n",
       "4          39         244      6.100000          19.5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(columns=['sent_count','punc_count','stopw_count','stopw_density'], inplace=True)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBnwBoEwSn3V"
   },
   "source": [
    "# Categorizing and Tagging Words\n",
    "Another group of features we can inspect in text data are the Part-Of-Speech tagging:\n",
    "\n",
    "*The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging, POS-tagging, or simply tagging. Parts of speech are also known as word classes or lexical categories... The collection of tags used for a particular task is known as a tagset. Our emphasis in the next section is on exploiting tags, and tagging text automatically.*\n",
    "\n",
    "       Natural Language Processing with Python, by S. Bird, E. Klein and E. Loper [1]\n",
    "\n",
    "Our target in the next section is to identify the POS tags and analyze its distribution on the dataset. Maybe we can observe any interesting behavior but it is not frequent.\n",
    "\n",
    "Tag Meaning English Examples:\n",
    "- ADJ, adjective: new, good, high, special, big, local\n",
    "- ADP,adposition:on, of, at, with, by, into, under\n",
    "- ADV, adverb: really, already, still, early, now\n",
    "- CONJ, conjunction: and, or, but, if, while, although\n",
    "- DET, determiner or article: the, a, some, most, every, no, which\n",
    "- NOUN, noun: year, home, costs, time, Africa\n",
    "- NUM,numeral: twenty-four, fourth, 1991, 14:24\n",
    "- PRT, particle: at, on, out, over per, that, up, with\n",
    "- PRON, pronoun: he, their, her, its, my, I, us\n",
    "- VERB, verb: is, say, told, given, playing, would\n",
    "- ., punctuation marks:. , ; !\n",
    "- X, othe: ersatz, esprit, dunno, gr8, univeristy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1679079342499,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "qqAOAevzSn3V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pos_tags(indexes, sentences, tagset='universal'):\n",
    "    ''' Extract the part-of-speech taggings of the sentence\n",
    "        Input:\n",
    "        - sentence: string, sentence to tag\n",
    "        - tagset: string, tagset or the set of tags to search for\n",
    "    '''\n",
    "    #Create the Dataframe to store the count of tags\n",
    "    df = pd.DataFrame(columns=['ADJ','ADP','ADV','CONJ','DET','NOUN','NUM','PRT','PRON','VERB','.','X'])\n",
    "    for ind, sent in zip(indexes, sentences):\n",
    "        # Extract the part of Speech tags in the sentence\n",
    "        pos_tags = Counter([j for i,j in nltk.pos_tag(word_tokenize(sent), tagset='universal')])\n",
    "        #Appends the pos tags to the dataframe, fill NaN values with 0\n",
    "        #df = df.append(pos_tags, ignore_index=True).fillna(0)\n",
    "        #df = df.append(pos_tags, ignore_index=True).fillna(0)\n",
    "        df = pd.concat([df, pd.DataFrame([pos_tags], index=[ind])], ignore_index=False).fillna(0)\n",
    "\n",
    "    return df.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM_NgNZeSn3V"
   },
   "source": [
    "To help us with this task, the NLTK library defines a function `pos_tag` which receive a list of words as input and return the part-of-speech tag of every word. Then we can plot a histogram to check the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 62233, 62234, 62235]),\n",
       " array(['company reporting three unknown account credit report unfair practice company called several time claim find account social security number possible reporting',\n",
       "        'recall record boss requested various occasion send verification proprietorship however agreed solicitation yet',\n",
       "        'merchant committed fraud shipping incorrect item ignored request correct situation although disputed transaction citicard aka citibank month later within allowable dispute period matter still resolved three month later despite frequent request update citicard ultimately denied recovery money citicard much time passed unacceptable since passing time due delay citicard fraudulent merchant specific detail follow purchased large inflatable water slide xxxxadvertised merchant located prompt shipping business day promised however month later still received item tracking number given still showed preparing shipment email request merchant regarding status update ignored disputed transaction citicard received response would given conditional credit investigated transaction hear anything else matter package finally arrived merchant however contain large inflatable water slide contained one pair sock called citicard day let know believed merchant trying defraud citicard informed would need wait official email communication citicard continue update dispute day later received communication citicard merchant proven shipment delivery therefore citicard would reverse conditional credit close dispute responded citicard email fax usps mail using provided form satisfied resolution merchant indeed committed fraud solid proof believed merchant deliberately working within citicard known policy order carry fraud receive another response citicard requested information including receipt etc warning return requested information next day replied day requested proof including receipt advertisement email attempt merchant resolution picture ordered v shipped confusingly received two email response citicard received email stating received dispute information dispute still day later received secure message linking document backdated stating previously requested necessary additional information email concerning dispute receive response dispute closed finally received another secure message time frame resolve dispute sent citicard strongly worded email stating delay side would let go continue contact resolution may close several citicard credit card account since longer seen trustworthy may seek legal counsel matter honestly hope remuneration merchant feel citicard held accountable complicity',\n",
       "        ...,\n",
       "        'recently filed complaint believe explained correctly claiming owe debt reached provide proof debt initial complaint responded saying sent first collection letter last known address address file last year never received letter owe collection received copy contract submitted complaint contract show two name know person contract also owe debt never lived address contract never credit file owe lake debt sure address file yet isnt georgia address file moved see name need adequate proof owe collection would like see actual social security number tie collection name cause im one name also legit signed contract computerized signature actual signature social security number debt every detrimental credit asking removed credit action taken',\n",
       "        'asked couple time update profile always later informed ssn already used another bank customer different state provided bank ssn card government issued id update purpose however made understand customer using ssn opened credit card account ssn led reason filing report last year platform contacted social security office make complain advised file report local police dept also contacted three bureau contacting equifax equifax confirmed information provided match one record asked document identity verification last year equifax sent mail stating ssn belongs deceased person faxing document umpteenth time equifax helping fix problem equifax declined dissociating ssn equifax declined identifying full correct legal name requested verification document faxed equifax',\n",
       "        'ive trying get day extension care act informs u entitled three month ago called informed got three month forbearance didnt know recently called back bank spoke representative informed could get three month forbearance dont know able qualify per care act need two day extension needed bank inform later already extension day supposed day something paper guarantee right ask future needed one year dont know bank honor full year future three month increment providing option giving date first three month forbearance'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['narrative'].index.values,dataset['narrative'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62236, 62236)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['narrative'].index.values), len(dataset['narrative'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "n4Y29NykSn3V",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>.</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADJ  ADP  ADV  CONJ  DET  NOUN  NUM  PRT  PRON  VERB  .  X\n",
       "0    5    0    0     0    0    12    1    0     0     3  0  0\n",
       "1    1    0    2     0    0     7    0    0     0     3  0  0\n",
       "2   51    6   25     0    2   123    3    0     0    83  0  1\n",
       "3    7    0    3     0    0    20    0    0     0     6  0  0\n",
       "4    8    0    3     0    0    22    0    0     0     6  0  0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the taggings for the text variable\n",
    "#text = dataset['narrative'].values\n",
    "df_text = get_pos_tags(dataset['narrative'].index.values, dataset['narrative'].values)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62236, 62236)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset),len(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_tagged = pd.concat([dataset, df_text], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>sent_density</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>.</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>company reporting three unknown account credit...</td>\n",
       "      <td>21</td>\n",
       "      <td>138</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>recall record boss requested various occasion ...</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>merchant committed fraud shipping incorrect it...</td>\n",
       "      <td>294</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>147.0</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>sent debt validation letter company failed val...</td>\n",
       "      <td>36</td>\n",
       "      <td>245</td>\n",
       "      <td>6.621622</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>phoenix financial service llc company claiming...</td>\n",
       "      <td>39</td>\n",
       "      <td>244</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>19.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           product                                          narrative  \\\n",
       "0  debt_collection  company reporting three unknown account credit...   \n",
       "1  debt_collection  recall record boss requested various occasion ...   \n",
       "2      credit_card  merchant committed fraud shipping incorrect it...   \n",
       "3  debt_collection  sent debt validation letter company failed val...   \n",
       "4  debt_collection  phoenix financial service llc company claiming...   \n",
       "\n",
       "   word_count  char_count  word_density  sent_density  ADJ  ADP  ADV  CONJ  \\\n",
       "0          21         138      6.272727          10.5    5    0    0     0   \n",
       "1          13          98      7.000000           6.5    1    0    2     0   \n",
       "2         294        2006      6.800000         147.0   51    6   25     0   \n",
       "3          36         245      6.621622          18.0    7    0    3     0   \n",
       "4          39         244      6.100000          19.5    8    0    3     0   \n",
       "\n",
       "   DET  NOUN  NUM  PRT  PRON  VERB  .  X  \n",
       "0    0    12    1    0     0     3  0  0  \n",
       "1    0     7    0    0     0     3  0  0  \n",
       "2    2   123    3    0     0    83  0  1  \n",
       "3    0    20    0    0     0     6  0  0  \n",
       "4    0    22    0    0     0     6  0  0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset_tagged))\n",
    "dataset_tagged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sent letter asking security freeze placed consumer disclosure report didnt receive correspondence also sent second letter asking place security freeze report still'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tagged.iloc[1000, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_tags = Counter([j for i,j in nltk.pos_tag(word_tokenize(dataset_tagged.iloc[1000, 1]), tagset='universal')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product                                          credit_reporting\n",
       "narrative       sent letter asking security freeze placed cons...\n",
       "word_count                                                     22\n",
       "char_count                                                    142\n",
       "word_density                                             6.173913\n",
       "sent_density                                                 11.0\n",
       "ADJ                                                             3\n",
       "ADP                                                             0\n",
       "ADV                                                             2\n",
       "CONJ                                                            0\n",
       "DET                                                             0\n",
       "NOUN                                                           12\n",
       "NUM                                                             0\n",
       "PRT                                                             0\n",
       "PRON                                                            0\n",
       "VERB                                                            5\n",
       ".                                                               0\n",
       "X                                                               0\n",
       "Name: 1000, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tagged.iloc[1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADJ      3\n",
       "NOUN    12\n",
       "VERB     5\n",
       "ADV      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5A3e2Rv6Sn3W"
   },
   "outputs": [],
   "source": [
    "# Select the columns to plot: those related to pos taggings\n",
    "plot_vars=np.array([['ADJ','ADP','ADV','CONJ','DET','NOUN']])\n",
    "# Plot a histograms of the variables \n",
    "plot_histograms(df_text, plot_vars, [20, 30, 10, 10, 20, 25], labels_dict, figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVgo0x7tSn3b"
   },
   "source": [
    "# Most frequent terms and Wordclouds\n",
    "\n",
    "The domain or context of our texts will determine the most frequent words, therefore, it is important to verify what those words are and thus identify the domains and confirm that they are the expected ones.\n",
    "\n",
    "A Wordcloud (or Tag cloud) is a visual representation of text data. It displays a list of words and the importance of each beeing shown with font size or color (the bigger the more frequent). This format is useful for quickly perceiving the most relevant terms on a document or set of documents.\n",
    "\n",
    "We will draw the wordcloud for the source texts and the summaries to compare if they are very similar, it will allow us to check that the relevant concepts have been correctly extracted in the summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga6o_l2QSn3b"
   },
   "source": [
    "Build the wordcloud for every category and we compare the results to get a better understanding of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1679162511433,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "-B3KqUGzSn3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#A function to create a wordcloud image\n",
    "def wordcloud_image(text, dir, name, max_words):\n",
    "  # Join the different processed texts together.\n",
    "  #long_string = ','.join(list(cleaned_text.values))\n",
    "  # Create a WordCloud object\n",
    "  wordcloud = WordCloud(background_color=\"white\", max_words=max_words, contour_width=3, contour_color='steelblue')\n",
    "  # Generate a word cloud\n",
    "  wordcloud.generate(text)\n",
    "  # Visualize the word cloud\n",
    "  image = wordcloud.to_image()\n",
    "  #Save the image\n",
    "  image.save(dir+\"/\"+name+\".jpg\")\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 34352,
     "status": "ok",
     "timestamp": 1679162548237,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "dqW6uudh0RBS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#category=\"credit_reporting\"\n",
    "#dataset[dataset[\"product\"]==category][\"narrative\"].values\n",
    "#dataset[\"product\"].unique()\n",
    "os.makedirs(\"wordclouds\", exist_ok=True)\n",
    "for category in dataset[\"product\"].unique():\n",
    "  # Create a Wordcloud for the category\n",
    "  wordc= wordcloud_image(','.join(list(dataset[dataset[\"product\"]==category][\"narrative\"].values)), \"wordclouds\", \"wordcloud_\"+category, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include a column to identify the project, it could be useful for some future processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset['project']='consumer_complaints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf5D9H8Dsk8h"
   },
   "source": [
    "## W&B Tables to save our information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9SvAqDKsqvF"
   },
   "source": [
    "We can use W&B features to track our experiments, register relevant information and storage our datasets or figures. It will be our project repository, all data and information just in one place we can restore o report later. To define a Table, we just to specify the columns you want for each row and a row might be a single item in your training dataset, a prediction or an epoch during training.\n",
    "\n",
    "A simple way to create a table is from a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1679165842006,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "WMQkQFHvuEKH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"consumer_complaints_classification\"\n",
    "ENTITY = None # set this to team name if working in a team\n",
    "RAW_DATA_AT = 'consumer_complaints_eda'\n",
    "PROCESSED_DATA_AT = 'consumer_complaints_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "executionInfo": {
     "elapsed": 11132,
     "status": "ok",
     "timestamp": 1679162731606,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "f_2_2wESuDHB",
    "outputId": "9ab4f3d8-fee3-4cce-9ecc-bd4f0cbe975c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33medumunozsala\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/sagemaker-studiolab-notebooks/wandb/run-20230827_164606-xvfdqjmy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/xvfdqjmy' target=\"_blank\">dark-dust-1</a></strong> to <a href='https://wandb.ai/edumunozsala/consumer_complaints_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/edumunozsala/consumer_complaints_classification' target=\"_blank\">https://wandb.ai/edumunozsala/consumer_complaints_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/xvfdqjmy' target=\"_blank\">https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/xvfdqjmy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Init W&B session in the project\n",
    "run = wandb.init(project=WANDB_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gHL8ZMA5unE"
   },
   "source": [
    "Create an Artifact to save the results of our data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1679162833121,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "dZavZhdA5ny6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data_at = wandb.Artifact(RAW_DATA_AT, type=\"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1679163122607,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "3CblWP0l54dN",
    "outputId": "d8fae8e6-3eb8-4b70-8499-edd7f619d1c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./wordclouds)... Done. 0.0s\n"
     ]
    }
   ],
   "source": [
    "#Save the Wordcloud images for every category\n",
    "raw_data_at.add_dir('wordclouds', name='worcloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9260,
     "status": "ok",
     "timestamp": 1679163187227,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "Tf687QYo5JZk",
    "outputId": "b3219258-cadc-4ec5-949a-b91168983202",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.artifacts.artifact_manifest_entry.ArtifactManifestEntry at 0x7fd3c5b06790>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a W&B table\n",
    "table = wandb.Table(dataframe=dataset)\n",
    "# Save it in the artifact\n",
    "raw_data_at.add(table, \"eda_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 6074,
     "status": "ok",
     "timestamp": 1679163202818,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "q7Dl3Zr46lg-",
    "outputId": "31b2bf4d-b57e-4b7d-9501-95e7185fca2b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-dust-1</strong> at: <a href='https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/xvfdqjmy' target=\"_blank\">https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/xvfdqjmy</a><br/>Synced 6 W&B file(s), 0 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230827_164606-xvfdqjmy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.log_artifact(raw_data_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOC0eN-RDfex"
   },
   "source": [
    "# Preparing the dataset for spliting into train, validation and test sets.\n",
    "\n",
    "We will repeat the process to reduce row counts to get a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1679158968079,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "tCpR7WNBD_h6",
    "outputId": "98c10e68-c13c-4c1f-ecfd-97a9d4522918",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "credit_reporting       56240\n",
       "debt_collection        21057\n",
       "mortgages_and_loans    18723\n",
       "credit_card            14983\n",
       "retail_banking         13469\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL-fk5-eESw9"
   },
   "source": [
    "### Category 'credit_reporting'.\n",
    "\n",
    "To limit this unbalanced feature we will downsample our data to only 15,000 rows in the categories: `credit_reporting`,`debt_collection`, mortgages_and_loans` . And for the sake of this experiment this step will reduce our data volume and we can perform a shorter and cheaper training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1679158970535,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "pInTKIMSE-AX",
    "outputId": "b1e3e54c-a3e0-422e-8849-e82ea68743fa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56240, 2)\n",
      "(21057, 2)\n",
      "(18723, 2)\n"
     ]
    }
   ],
   "source": [
    "credit = data[data[\"product\"] == \"credit_reporting\"]\n",
    "debt  = data[data[\"product\"] == \"debt_collection\"]\n",
    "mortgage  = data[data[\"product\"] == \"mortgages_and_loans\"]\n",
    "print(credit.shape)\n",
    "print(debt.shape)\n",
    "print(mortgage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679158973134,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "3acoCZExHuNk",
    "outputId": "71444ac4-e539-4d62-d736-95eed89d0002",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 2)\n",
      "(15000, 2)\n",
      "(15000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Sample the three columns in the dataset to extract 15,000 rows\n",
    "credit = credit.sample(n=15000, replace=False, random_state=42)\n",
    "debt = debt.sample(n=15000, replace=False, random_state=42)\n",
    "mortgage = mortgage.sample(n=15000, replace=False, random_state=42)\n",
    "print(credit.shape)\n",
    "print(debt.shape)\n",
    "print(mortgage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh8vd7NdmBH0"
   },
   "source": [
    "Now, we build a new dataframe concatening these samples and the others two originals columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1679159012845,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "kIez29jzI7b4",
    "outputId": "72a43814-fd30-4e49-dcce-acf2fb188d6c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>please remove highlighted account credit repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>experian violation section fair credit reporti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>experian continues report false information cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>listed belong someone stole used social securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>complained year equifax done nothing update co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            product                                          narrative\n",
       "0  credit_reporting  please remove highlighted account credit repor...\n",
       "1  credit_reporting  experian violation section fair credit reporti...\n",
       "2  credit_reporting  experian continues report false information cr...\n",
       "3  credit_reporting  listed belong someone stole used social securi...\n",
       "4  credit_reporting  complained year equifax done nothing update co..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced=pd.concat([credit, debt, mortgage, data[data[\"product\"] == \"credit_card\"], data[data[\"product\"] == \"retail_banking\"]], ignore_index=True)\n",
    "data_balanced.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1679078135900,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "lgKIQFbtJNrO",
    "outputId": "8b6a8f5a-2d31-4829-ae35-b8bca21c7462",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "credit_reporting       15000\n",
       "debt_collection        15000\n",
       "mortgages_and_loans    15000\n",
       "credit_card            14983\n",
       "retail_banking         13469\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the count of rows for every category\n",
    "data_balanced['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eVRHqpOBWu6"
   },
   "source": [
    "## Split the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=data_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1679165706591,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "I3P7xxBNBbiV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the data into train and test set\n",
    "train_df, test_df = train_test_split(dataset[[\"product\",\"narrative\"]], test_size=0.3, random_state=42, shuffle=True, stratify=dataset[\"product\"])\n",
    "# split the data into train and test set\n",
    "val_df, test_df = train_test_split(test_df[[\"product\",\"narrative\"]], test_size=0.5, random_state=42, shuffle=True, stratify=test_df[\"product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1679165958589,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "OateFUfrFnYa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"stage\"]=\"train\"\n",
    "val_df[\"stage\"]=\"validation\"\n",
    "test_df[\"stage\"]=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1679166065147,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "VRYtEJPlER6s",
    "outputId": "79600809-080f-487c-8a2c-974c18afc56d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>card hacked called able cancel card order repl...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debt_collection</td>\n",
       "      <td>received letter convergent outsourcing inc was...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>much time many error law broken funny year try...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>past two month trying get total hard inquiry r...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>reporting outrageous erroneous debt credit fil...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            product                                          narrative  stage\n",
       "0       credit_card  card hacked called able cancel card order repl...  train\n",
       "1   debt_collection  received letter convergent outsourcing inc was...  train\n",
       "2  credit_reporting  much time many error law broken funny year try...  train\n",
       "3  credit_reporting  past two month trying get total hard inquiry r...  train\n",
       "4  credit_reporting  reporting outrageous erroneous debt credit fil...  train"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split=pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "data_split.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1679166155469,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "f19Q9kJYGPDh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_split.to_csv(\"consumer_complaints_split.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAFHMEAzFNkL"
   },
   "source": [
    "We will now create a new artifact and add our data there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "executionInfo": {
     "elapsed": 3389,
     "status": "ok",
     "timestamp": 1679166436774,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "ozqE1N9oDlZp",
    "outputId": "ef55d0f0-ff4e-48de-94f3-2488d631a86f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/sagemaker-studiolab-notebooks/wandb/run-20230827_172634-zc3ulrfi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/zc3ulrfi' target=\"_blank\">zany-frost-4</a></strong> to <a href='https://wandb.ai/edumunozsala/consumer_complaints_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/edumunozsala/consumer_complaints_classification' target=\"_blank\">https://wandb.ai/edumunozsala/consumer_complaints_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/zc3ulrfi' target=\"_blank\">https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/zc3ulrfi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.artifacts.artifact_manifest_entry.ArtifactManifestEntry at 0x7fd3c97c52e0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAve the data to W&B\n",
    "run = wandb.init(project=WANDB_PROJECT, job_type=\"data_split\")\n",
    "processed_data_at = wandb.Artifact(PROCESSED_DATA_AT, type=\"split_data\")\n",
    "processed_data_at.add_file(\"consumer_complaints_split.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsPBDUGLG1Yf"
   },
   "source": [
    "And we will upload the data as a table to our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5963,
     "status": "ok",
     "timestamp": 1679166450228,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "XwNCzK5LG53l",
    "outputId": "9f2ba049-065c-4b1e-bb99-01fdc0dd9574",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.artifacts.artifact_manifest_entry.ArtifactManifestEntry at 0x7fd3c97a4700>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split_table = wandb.Table(dataframe=data_split)\n",
    "processed_data_at.add(data_split_table, \"table_data_split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxsXKnL5HQrF"
   },
   "source": [
    "finally we save the artifact ain W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 5498,
     "status": "ok",
     "timestamp": 1679166458452,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "55nrfIbPHVsk",
    "outputId": "a993a86e-243c-4439-9a0a-ceec609ae94c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-frost-4</strong> at: <a href='https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/zc3ulrfi' target=\"_blank\">https://wandb.ai/edumunozsala/consumer_complaints_classification/runs/zc3ulrfi</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230827_172634-zc3ulrfi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.log_artifact(processed_data_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeeOVgCtSn3c"
   },
   "source": [
    "## Optional section: Topic Modelling\n",
    "\n",
    "In our next step, we will learn how to identity which topics are discussed in our texts, this process is called topic modelling. **\"In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents\"** by Wikipedia. Using a unsupervised technique, this method tries to find semantic structures in a text in order to classified group of related words in a topic representation.\n",
    "\n",
    "In particular, we will cover Latent Dirichlet Allocation (LDA): a widely used topic modelling technique. And we will apply LDA to convert our set of source texts to a set of topics.\n",
    "\n",
    "*There are several existing algorithms you can use to perform the topic modeling. The most common of it are, Latent Semantic Analysis (LSA/LSI), Probabilistic Latent Semantic Analysis (pLSA), and Latent Dirichlet Allocation (LDA)*\n",
    "\n",
    "[5], \"Topic Modeling in Python: Latent Dirichlet Allocation (LDA)\" by Shashank Kapadia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RisOGARhSn3c"
   },
   "source": [
    "But first, we need to transform our text data to a format that will serve as an input to the LDA model. We convert the text to a vector representation where each word is replaced by an integer. In this case we will apply the CountVectorized method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyffSm6pSn3d"
   },
   "source": [
    "## Count Vectorized\n",
    "\n",
    "The Count Vectorizeed method replace each word by the count of occurrences of the word in our corpus, group of texts. The result is a document term matrix where most frequents words are assigned with a higher value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ndj1NCt1Sn3d"
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def plot_10_most_common_words(count_data, count_vectorizer):\n",
    "    ''' Draw a barplot showing the tenth most common words in the data\n",
    "        Input:\n",
    "        - count_data: tuple, containing pairs of document-term and its ocurrencies in the text\n",
    "        - count_vectorizer: CountVectorizer object\n",
    "    '''\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n",
    "    words = [w[0] for w in count_dict]\n",
    "    counts = [w[1] for w in count_dict]\n",
    "    x_pos = np.arange(len(words)) \n",
    "    \n",
    "    plt.figure(2, figsize=(15, 15/1.6180))\n",
    "    plt.subplot(title='10 most common words')\n",
    "    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "    sns.barplot(x_pos, counts, palette='husl')\n",
    "    plt.xticks(x_pos, words, rotation=90) \n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('counts')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1555,
     "status": "ok",
     "timestamp": 1611514733256,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "vqc4tKCqSn3d",
    "outputId": "c4a3944d-77ae-4d30-dd90-506ab3d8911a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       acacia  accessory  accompanied  ...  zipped  zips  zipup\n",
      "0           0          0            0  ...       0     0      1\n",
      "1           0          0            0  ...       0     0      0\n",
      "2           0          0            0  ...       0     0      0\n",
      "3           0          0            0  ...       0     0      0\n",
      "4           0          0            0  ...       0     0      0\n",
      "...       ...        ...          ...  ...     ...   ...    ...\n",
      "33608       0          0            0  ...       0     0      0\n",
      "33609       0          0            0  ...       0     0      0\n",
      "33610       0          0            0  ...       0     0      0\n",
      "33611       0          0            0  ...       0     0      0\n",
      "33612       0          0            0  ...       0     0      0\n",
      "\n",
      "[33613 rows x 1427 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialise the count vectorizer\n",
    "tf_vectorizer = CountVectorizer(max_df=0.9, min_df=25, max_features=5000)\n",
    "# Apply the count vectorized method to our cleaned data\n",
    "tf = tf_vectorizer.fit_transform(cleaned_text)\n",
    "# Build the Document Term Matrix\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "doc_term_matrix = pd.DataFrame(tf.toarray(), columns=list(tf_feature_names))\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "executionInfo": {
     "elapsed": 2580,
     "status": "ok",
     "timestamp": 1611514739060,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "M7mW3MzpSn3d",
    "outputId": "32f378c6-d5b3-4338-82f5-43d019b66f94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x667.491 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise the 10 most common words\n",
    "plot_10_most_common_words(tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSRgKJXkSn3e"
   },
   "source": [
    "## Extract the topic modelling\n",
    "\n",
    "The next cells will allow us to discover topics in our texts, group of words with co-ocurrences in the documents. The Scikit-learn library provides a function to calculate LDA and return a list with the topic and the tokens that include. In our example, we define 10 topics to discover and show the main 8 elements or words in each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TXSdSrtSn3e"
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    ''' Print the topics detected and the n_top_words that contains\n",
    "    Input:\n",
    "       - model: LDA model for the text\n",
    "       - count_cectorizer: the count vectorizer object\n",
    "       - n_top_words: the number of words to consider in a topic\n",
    "    '''\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2423855,
     "status": "ok",
     "timestamp": 1611517315278,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "5PVYRDYASn3e",
    "outputId": "6c3c3db6-e908-4765-e461-ce683d9c4519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "cm strap length bag width black insole shoulder\n",
      "\n",
      "Topic #1:\n",
      "design elastic highwaist waistband trim decorative puff wax\n",
      "\n",
      "Topic #2:\n",
      "round print tshirt short neckline sleeves front featuring\n",
      "\n",
      "Topic #3:\n",
      "cotton notes fragrance candle ml zara de oz\n",
      "\n",
      "Topic #4:\n",
      "front sleeves long collar featuring pockets fastening shirt\n",
      "\n",
      "Topic #5:\n",
      "detail fastening back leather dress belt zip applique\n",
      "\n",
      "Topic #6:\n",
      "front pockets zip adjustable fastening button elastic side\n",
      "\n",
      "Topic #7:\n",
      "cm model height chest back fit lapel side\n",
      "\n",
      "Topic #8:\n",
      "print floral two pack one bow cover pull\n",
      "\n",
      "Topic #9:\n",
      "sleeves long round neck neckline trims cm model\n"
     ]
    }
   ],
   "source": [
    "# Apply the LDA method to discover the topics\n",
    "lda_model = LDA(n_components=10, learning_method='online', max_iter=500, random_state=0).fit(tf)\n",
    "# Show the topics and the 8 more relevant words in each topic\n",
    "no_top_words = 8\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda_model, tf_vectorizer, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHdgd5G7Sn3e"
   },
   "source": [
    "In our dataset, all news are closely related and include terms like said, india, people. It is hard to clearly identify the topics, but for example, number 4 looks like it is referencing to politicians and number 3 to a sport competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAOzAq-ZSn3f"
   },
   "source": [
    "## Visualizing the topic modelling results\n",
    "\n",
    "Visualizing the topics will help us to interpret them, the **pyLDAvis** library plot an interactive figure where each circle corresponds to a topic. The size of the circle represent its importance in the texts and the distance between each circke indicates how similar they are. You can select a topic to display the most relevant words for the topic and the frequency of each word appearing in the topic and the corpus.\n",
    "\n",
    "The parameter relevance metric λ distinguishes words which are exclusive to the topic (closer to 0) and words with high probability of being included in the selected topic (closer to 1). Playing around with this parameter can help us to assign a \"name\" to a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AWAihSJSn3f",
    "outputId": "05de1a8c-2eff-421c-b169-fc89bcbad333"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edumu\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "LDAvis_data_filepath = os.path.join(output_path+'ldavis_prepared_'+str(number_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "#if 1 == 1:\n",
    "\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda, count_data, count_vectorizer)\n",
    "with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath,'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "    \n",
    "pyLDAvis.save_html(LDAvis_prepared, LDAvis_data_filepath+'.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8r6gcQSuSn3f"
   },
   "source": [
    "In the figure shown, we can select a topic and review which relevants words include, its frequency in the dataset. It is easy to compare topics, and search for anomalies or points to mention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R07P1vRSn3f"
   },
   "source": [
    "# References:\n",
    "\n",
    "[1]. Natural Language Processing with Python, by Steven Bird, Ewan Klein and Edward Loper, 2019.\n",
    "\n",
    "[3]- Hovy, E. H. Automated Text Summarization. In R. Mitkov (ed), The Oxford Handbook of Computational Linguistics, chapter 32, pages 583–598. Oxford University Press, 2005\n",
    "\n",
    "[4]- Mani, I., House, D., Klein, G., et al. The TIPSTER SUMMAC Text Summarization Evaluation. In Proceedings of EACL, 1999.\n",
    "\n",
    "[5]- Shashank Kapadia, [\"Topic Modeling in Python: Latent Dirichlet Allocation (LDA)\"](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0) 2019 Medium post.\n",
    "\n",
    "[6]- Susan Li, [\"Topic Modelling in Python with NLTK and Gensim\"](https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21) 2018 Medium post\n",
    "\n",
    "Kaggle kernels of interest:\n",
    "\n",
    "https://www.kaggle.com/shivamb/seconds-from-disaster-text-eda-and-analysis\n",
    "\n",
    "https://www.kaggle.com/caractacus/thematic-text-analysis-using-spacy-networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IK8fGn-Sn3g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vAOzAq-ZSn3f"
   ],
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
